{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69fd984a-3a14-484a-9b93-f4d28bde9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e24b3d2d-0f41-4ce6-8c2b-d6d7ccf5737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Width  Thickness  Speed  TPH  GSM-A    JCF  JCF1  JCF2   JCF3  JCF4  ...  \\\n",
      "0  1236.00       2.00     29   40  313.0  29.63    50    35  32.09    33  ...   \n",
      "1    29.55       3.40     25   41  282.0  29.00    50    35  32.00    33  ...   \n",
      "2  2851.00       2.50     29   40  282.0  29.00    50    35  32.00    33  ...   \n",
      "3  2702.00       2.00     29   32  282.0  29.00    50    36  32.00    33  ...   \n",
      "4  1004.00       0.98     65   30   85.0  23.00    50    28  26.00    27  ...   \n",
      "\n",
      "   NOF3  NOF4  NOF5  RTF1  RTF2  RTF3  JCFEN_STRIP_C  JCFEX_STRIP_C  \\\n",
      "0  1200  1119  1152   769   777   685            768            443   \n",
      "1  1200  1104  1137   768   773   684            471            510   \n",
      "2  1200  1100  1133   768   790   717            668            620   \n",
      "3  1200  1116  1149   771   770   700            698            618   \n",
      "4  1200  1160  1190   714   710   644            808            605   \n",
      "\n",
      "   Pot Temperature  Hardness  \n",
      "0              467      79.0  \n",
      "1              472      79.0  \n",
      "2              478       NaN  \n",
      "3              474       NaN  \n",
      "4              461      56.0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 754 entries, 0 to 753\n",
      "Data columns (total 23 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Width            754 non-null    float64\n",
      " 1   Thickness        754 non-null    float64\n",
      " 2   Speed            754 non-null    int64  \n",
      " 3   TPH              754 non-null    int64  \n",
      " 4   GSM-A            754 non-null    float64\n",
      " 5   JCF              754 non-null    float64\n",
      " 6   JCF1             754 non-null    int64  \n",
      " 7   JCF2             754 non-null    int64  \n",
      " 8   JCF3             754 non-null    float64\n",
      " 9   JCF4             754 non-null    int64  \n",
      " 10  JCF5             754 non-null    int64  \n",
      " 11  NOF1             754 non-null    int64  \n",
      " 12  NOF2             754 non-null    int64  \n",
      " 13  NOF3             754 non-null    int64  \n",
      " 14  NOF4             754 non-null    int64  \n",
      " 15  NOF5             754 non-null    int64  \n",
      " 16  RTF1             754 non-null    int64  \n",
      " 17  RTF2             754 non-null    int64  \n",
      " 18  RTF3             754 non-null    int64  \n",
      " 19  JCFEN_STRIP_C    754 non-null    int64  \n",
      " 20  JCFEX_STRIP_C    754 non-null    int64  \n",
      " 21  Pot Temperature  754 non-null    int64  \n",
      " 22  Hardness         707 non-null    float64\n",
      "dtypes: float64(6), int64(17)\n",
      "memory usage: 135.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = r\"CGL_Model2_Data.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Strip whitespace from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Display the first few rows and data info\n",
    "print(data.head())\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0372797d-dce6-4f1e-9f18-a3f5a54f92f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in Hardness column: 47\n",
      "Number of NaN values in Hardness column after handling: 0\n",
      "count    754.000000\n",
      "mean      70.074965\n",
      "std       11.955708\n",
      "min       55.000000\n",
      "25%       60.000000\n",
      "50%       65.000000\n",
      "75%       78.000000\n",
      "max       98.000000\n",
      "Name: Hardness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the 'Hardness' column\n",
    "print(\"Number of NaN values in Hardness column:\", data['Hardness'].isna().sum())\n",
    "\n",
    "# Handle NaN values in the 'Hardness' column\n",
    "data['Hardness'] = data['Hardness'].fillna(data['Hardness'].mean())\n",
    "\n",
    "# Verify that NaN values have been handled\n",
    "print(\"Number of NaN values in Hardness column after handling:\", data['Hardness'].isna().sum())\n",
    "\n",
    "# Display summary statistics of the 'Hardness' column\n",
    "print(data['Hardness'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "607dfd16-9836-4d81-99d2-304461f2af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variables\n",
    "features = ['Width','Thickness','GSM-A','TPH','Hardness']\n",
    "target = ['Speed','NOF1','NOF2','NOF3','NOF4','NOF5','RTF1','RTF2','RTF3','JCF','JCF1','JCF2','JCF3','JCF4','JCFEN_STRIP_C','JCFEX_STRIP_C','Pot Temperature']\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c89c25f-f0c1-40c8-967c-dfc0420f4b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score for Speed:\n",
      "  Random Forest: 0.9752\n",
      "  XGBoost: 0.9871\n",
      "\n",
      "R^2 score for NOF1:\n",
      "  Random Forest: 0.9280\n",
      "  XGBoost: 0.8933\n",
      "\n",
      "R^2 score for NOF2:\n",
      "  Random Forest: 0.8952\n",
      "  XGBoost: 0.8462\n",
      "\n",
      "R^2 score for NOF3:\n",
      "  Random Forest: 0.8149\n",
      "  XGBoost: 0.7389\n",
      "\n",
      "R^2 score for NOF4:\n",
      "  Random Forest: 0.8677\n",
      "  XGBoost: 0.8322\n",
      "\n",
      "R^2 score for NOF5:\n",
      "  Random Forest: 0.8345\n",
      "  XGBoost: 0.8440\n",
      "\n",
      "R^2 score for RTF1:\n",
      "  Random Forest: 0.9111\n",
      "  XGBoost: 0.9122\n",
      "\n",
      "R^2 score for RTF2:\n",
      "  Random Forest: 0.9049\n",
      "  XGBoost: 0.8944\n",
      "\n",
      "R^2 score for RTF3:\n",
      "  Random Forest: 0.3042\n",
      "  XGBoost: 0.3236\n",
      "\n",
      "R^2 score for JCF:\n",
      "  Random Forest: 0.7044\n",
      "  XGBoost: 0.6550\n",
      "\n",
      "R^2 score for JCF1:\n",
      "  Random Forest: 1.0000\n",
      "  XGBoost: 1.0000\n",
      "\n",
      "R^2 score for JCF2:\n",
      "  Random Forest: 0.8138\n",
      "  XGBoost: 0.7708\n",
      "\n",
      "R^2 score for JCF3:\n",
      "  Random Forest: 0.7385\n",
      "  XGBoost: 0.7082\n",
      "\n",
      "R^2 score for JCF4:\n",
      "  Random Forest: 0.7590\n",
      "  XGBoost: 0.6652\n",
      "\n",
      "R^2 score for JCFEN_STRIP_C:\n",
      "  Random Forest: 0.6929\n",
      "  XGBoost: 0.7161\n",
      "\n",
      "R^2 score for JCFEX_STRIP_C:\n",
      "  Random Forest: 0.5915\n",
      "  XGBoost: 0.6491\n",
      "\n",
      "R^2 score for Pot Temperature:\n",
      "  Random Forest: 0.7295\n",
      "  XGBoost: 0.7642\n",
      "\n",
      "Average R^2 score:\n",
      "  Random Forest: 0.7921\n",
      "  XGBoost: 0.7765\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Initialize and train the XGBoost Regressor\n",
    "xgb_model = MultiOutputRegressor(XGBRegressor(n_estimators=100, random_state=42))\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "xgb_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate R^2 score for each target variable for both models\n",
    "rf_r2_scores = {}\n",
    "xgb_r2_scores = {}\n",
    "\n",
    "for i, col in enumerate(target):\n",
    "    rf_r2 = r2_score(y_test.iloc[:, i], rf_pred[:, i])\n",
    "    xgb_r2 = r2_score(y_test.iloc[:, i], xgb_pred[:, i])\n",
    "    \n",
    "    rf_r2_scores[col] = rf_r2\n",
    "    xgb_r2_scores[col] = xgb_r2\n",
    "    \n",
    "    print(f\"R^2 score for {col}:\")\n",
    "    print(f\"  Random Forest: {rf_r2:.4f}\")\n",
    "    print(f\"  XGBoost: {xgb_r2:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Calculate the average R^2 score for both models\n",
    "rf_avg_r2 = np.mean(list(rf_r2_scores.values()))\n",
    "xgb_avg_r2 = np.mean(list(xgb_r2_scores.values()))\n",
    "\n",
    "print(f\"Average R^2 score:\")\n",
    "print(f\"  Random Forest: {rf_avg_r2:.4f}\")\n",
    "print(f\"  XGBoost: {xgb_avg_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "80fe1546-93c7-46fb-b247-179ed8eb7ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rf_model.joblib\n",
      "Saved xgb_model.joblib\n",
      "Saved scaler.joblib\n",
      "Saved features.joblib\n",
      "Saved target.joblib\n",
      "Model export completed.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory path\n",
    "model_dir = r\"C:\\Users\\parim\\OneDrive\\Desktop\\JSW_CGL_Project2\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Function to save model if it doesn't exist\n",
    "def save_model(model, filename):\n",
    "    filepath = os.path.join(model_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        joblib.dump(model, filepath)\n",
    "        print(f\"Saved {filename}\")\n",
    "    else:\n",
    "        print(f\"{filename} already exists. Skipping.\")\n",
    "\n",
    "# Save models and scaler\n",
    "save_model(rf_model, \"rf_model.joblib\")\n",
    "save_model(xgb_model, \"xgb_model.joblib\")\n",
    "save_model(scaler, \"scaler.joblib\")\n",
    "\n",
    "# Save feature names and target names\n",
    "save_model(features, \"features.joblib\")\n",
    "save_model(target, \"target.joblib\")\n",
    "\n",
    "print(\"Model export completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
